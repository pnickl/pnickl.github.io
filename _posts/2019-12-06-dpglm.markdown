---
layout: post
title:  "Bayesian Inference for Regression Models using Nonparametric Infinite Mixtures"
date:   2019-12-05 23:59:59 +00:00
image: /images/dpglm2.png
categories: thesis
author: "Peter Nickl"
venue: "M.Sc. Thesis, Intelligent Autonomous Systems Lab, Department of Computer Science, Technical University of Darmstadt, Germany"
link: https://www.ias.informatik.tu-darmstadt.de/uploads/Team/HanyAbdulsamad/Nickl_Master_Thesis_2019.pdf
excerpt: We derive and implement approximate inference algorithms for an infinite mixture of local linear regression units with data-driven complexity adaptation. 
abstract: We derive and implement approximate inference algorithms for regression. The considered regression method is a probabilistic infinite mixture of local linear regression models that is generative in both inputs and outputs. Complexity is regularized without relying on heuristics. Local regression models are added and pruned automatically, based on the stick-breaking representation of the Dirichlet process prior. The choice of model is taken with applications to robotic control in mind. Those benefit from fast online learning and prediction, data-driven complexity adaptation, modeling of discontinuities, input-dependent noise modeling, and well-calibrated uncertainty quantification. Similar local curve fitting methods rely on computationally expensive Markov chain Monte Carlo schemes. We derive and implement a Gibbs sampling baseline and an efficient variational inference algorithm. We conduct an experimental study on illustrative small-scale and real-world robotic datasets to validate the method and to ablate hyperparameters. The outcome is a software library of inference algorithms for mixture models.
---